# Image Classifier API

This project implements an image classification API using a FastAPI backend and an ONNX model. The model is designed to classify images into one of 1000 ImageNet categories.

## Features

- FastAPI endpoint `/predict` for image classification.
- Uses an ONNX model with built-in preprocessing.
- Dockerized for easy deployment.
- CI pipeline using GitHub Actions to build the Docker image on every push.

## Project Structure

```
.
├── .github/workflows/        # GitHub Actions CI pipeline
│   └── docker-build.yml
├── app.py                    # FastAPI application
├── convert_to_onnx.py        # Script to convert PyTorch model to ONNX
├── Dockerfile                # Docker configuration for deployment
├── image_classifier.onnx     # The ONNX model file (generated by convert_to_onnx.py)
├── images/                   # Sample images for testing
├── model.py                  # OnnxModel class for loading and running the model
├── pytorch_model.py          # PyTorch model definition (Classifier class)
├── pytorch_model_weights.pth # Pre-trained weights for the PyTorch model
├── README.md                 # This file
├── requirements.txt          # Python dependencies
└── test.py                   # Unit tests
```

## Setup and Running Locally

### Prerequisites

- Python 3.8+
- pip

### Installation

1.  **Clone the repository:**
    ```bash
    git clone <repository-url>
    cd <repository-directory>
    ```

2.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    *Note: If `requirements.txt` is missing or incomplete, you might need to install packages like `fastapi`, `uvicorn`, `onnxruntime`, `Pillow`, `numpy` manually. The script `convert_to_onnx.py` also requires `torch` and `torchvision`.*

3.  **Generate the ONNX model (if not already present):**
    The `image_classifier.onnx` model is included in the repository. If you need to regenerate it (e.g., after changes to `pytorch_model.py` or `convert_to_onnx.py`):
    ```bash
    python convert_to_onnx.py
    ```
    This will create/overwrite `image_classifier.onnx`.

### Running the API Server

Once the setup is complete and `image_classifier.onnx` is present, run the FastAPI application using Uvicorn:

```bash
uvicorn app:app --host 0.0.0.0 --port 8000
```

The API will be accessible at `http://localhost:8000`.

## API Endpoint

### `POST /predict`

Upload an image to this endpoint to get a classification.

-   **Request:** `multipart/form-data` with an `image` field containing the image file.
-   **Response:** JSON object with `class_id` and `probabilities`.

**Example using cURL:**

```bash
curl -X POST -F "image=@images/n01440764_tench.jpg" http://localhost:8000/predict
```

Expected output (probabilities will vary slightly):
```json
{
  "my_result": {
    "class_id": 0,
    "probabilities": [ /* array of 1000 probabilities */ ]
  },
  "status_code": 200
}
```

## Model and Preprocessing

The application uses an ONNX model (`image_classifier.onnx`) for inference.
A key feature of this model is that **image preprocessing steps (resizing, normalization, etc.) are integrated directly into the ONNX graph.**
This means the `OnnxModel` class in `model.py` only needs to load the image, resize it to the expected input dimensions (224x224), and convert it to a float32 NumPy array with pixel values in the 0-255 range. The ONNX model itself handles the rest of the preprocessing internally.

## CI Pipeline (GitHub Actions)

This project includes a Continuous Integration (CI) pipeline defined in `.github/workflows/docker-build.yml`.
The CI pipeline is triggered on every `push` to the repository. Its main job is to:

1.  Check out the latest code.
2.  Build the Docker image using the `Dockerfile` present in the repository.
3.  Tag the Docker image with a unique name based on the current timestamp (e.g., `my-image-name:1678886400`).

This ensures that a buildable Docker image is always available and helps catch integration issues early.

## Deployment (Docker)

The application is designed to be deployed using Docker.

1.  **Build the Docker image:**
    (This step is also performed by the CI pipeline)
    ```bash
    docker build -t image-classifier-app .
    ```

2.  **Run the Docker container:**
    ```bash
    docker run -p 8000:8000 image-classifier-app
    ```
    The API will then be accessible on port 8000 of the Docker host.

## Testing

Unit tests are located in `test.py`. To run them:

```bash
python test.py
```
The tests verify the `OnnxModel`'s prediction capabilities using sample images and also check error handling for invalid inputs.
